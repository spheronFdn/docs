import { Callout } from "nextra/components";
import { Steps } from 'nextra/components'

# Deploy Your App on Spheron Console

This guide will walk you through the steps to deploy and access your app on Spheron. Follow these steps carefully to ensure a successful deployment.

<Callout type="info">
  New users automatically receive $20 in free credits to get started. If you don't see your credits, please reach out to us on [Discord](https://sphn.wiki/discord).
</Callout>

<Steps>
### Access the Spheron Console
1. Visit [console.spheron.network](https://console.spheron.network)
2. Log in to your account or create a new one if you haven't already
3. Deposit some credits to your balance to pay for the deployment by clicking on the **Deposit** button in the top right corner.

### Select Your GPU
1. Navigate to the **Marketplace** tab
2. Choose between two deployment options:
    - **Secure GPUs**: Enterprise-grade hardware in professional data centers
      - Higher reliability and stability
      - Higher cost but guaranteed performance
    - **Community GPUs**: Shared resources from community members
      - More cost-effective
      - May have variable performance
3. Browse available GPUs or use the search function to find specific models
4. Review pricing and specifications before selection

### Configure Your Deployment
1. Select the **Jupyter with PyTorch 2.4.1** template
   - Pre-configured with CUDA support
   - Includes all necessary dependencies for AI and LLM app development
2. Configure your deployment settings:
   - Set a secure password in the `JUPYTER_TOKEN` field
   - Adjust GPU count based on your needs
   - Choose your deployment duration
3. Review your configuration and click **Confirm**
4. Wait for deployment (typically under 60 seconds)

### Access Your Environment
1. Go to the **Overview** tab once deployment is complete
2. Locate the **py-cuda** service
3. Click the provided connection URL
4. Log in using your previously set password

<Callout type="warning">
  Make sure to save your JUPYTER_TOKEN password securely. You'll need it to access your environment.
</Callout>

### Start Developing
- Your environment comes pre-configured with:
  - Jupyter Notebook interface
  - PyTorch 2.4.1
  - CUDA support for GPU acceleration
  - Common ML/AI libraries
- All changes persist during your rental period
- You can install additional packages as needed
- You can also access the deployment shell to run any command you want and deployment logs to check the status of your deployment
</Steps>


## Verification
To verify GPU support:
1. Create a new Python notebook
2. Run the following code:
```python
import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
```
3. Or run this command to check the GPU count:
```bash
nvidia-smi
```

## Additional Tips
- Save your work regularly on Github.
- Monitor your memory usage carefully - if your notebook uses more memory than available (Out Of Memory/OOM), the server will automatically terminate and restart your notebook session, causing you to lose any unsaved work. You can check memory usage by running `nvidia-smi` in a notebook cell.
- Your deployment environment is dedicated to you and not shared with other users, ensuring optimal performance for your workloads.


Congratulations! Your app is now deployed and accessible. If you encounter any issues, reach out to [Spheron Discord Support](https://sphn.wiki/discord).