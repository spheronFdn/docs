import { Steps } from 'nextra/components'

# Running Jupyter Notebook with GPU Support

This guide walks you through deploying a Jupyter Notebook instance with GPU support on Spheron.

## Prerequisites
- Spheron account
- Basic familiarity with Jupyter Notebook
- Sufficient credits for GPU usage

## Deployment Steps

<Steps>
### 1. Access the Spheron Console
1. Navigate to [console.spheron.network](https://console.spheron.network)
2. Log in to your account
3. If you are new to Spheron, you should already have a free credits balance of $20. If not, please reach out to us on [Discord](https://sphn.wiki/discord) to get a free credits balance.

### 2. Select a GPU
1. Go to **Marketplace** tab
2. You have 2 options to choose from:
    - **Secure**: For deploying on secure and data center grade provider. It is super reliable but costs more.
    - **Community**: For deploying on community fizz nodes that are running on someones home machine. It might not be very reliable.
3. Now select any GPU you want to deploy on. You can also search the GPU name to find the exact GPU you want to deploy on.

### 3. Configure the Deployment
1. Select the template **Jupyter with Pytorch 2.4.1**
2. Put any password in `JUPYTER_TOKEN` field that you want to set for the Jupyter Notebook
3. If you want you can increase the GPU count to access multiple GPUs at once.
4. You can select the duration of the deployment.
5. Click on **Confirm** button to start the deployment
6. Deployment will be done in less than 60 seconds

### 4. Access the Jupyter Notebook
1. Once deployed, go to **Overview** tab.
2. Click on **py-cuda** service to open the Jupyter Notebook service.
3. Click on the connection url to open the Jupyter Notebook.
4. Use the password you set in the previous step to log in.
</Steps>

## Verification
To verify GPU support:
1. Create a new Python notebook
2. Run the following code:
```python
import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
```
3. Or run this command to check the GPU count:
```bash
nvidia-smi
```

## Additional Tips
- Save your work regularly on Github.
- Monitor your memory usage carefully - if your notebook uses more memory than available (Out Of Memory/OOM), the server will automatically terminate and restart your notebook session, causing you to lose any unsaved work. You can check memory usage by running `nvidia-smi` in a notebook cell.
